{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor, BaggingRegressor, AdaBoostClassifier, RandomForestRegressor\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyRegressor\n",
    "import lightgbm\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = './data/train_preprocess.csv'    # origin path 'data/train_pyspark.csv'\n",
    "test_data = './data/test_preprocess.csv'      # origin path 'data/test_pyspark.csv'\n",
    "\n",
    "train = pd.read_csv(train_data, sep='\\t')\n",
    "test = pd.read_csv(test_data, sep='\\t')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.dropna() # clean empty values\n",
    "train_y = np.array(train_x['Correct First Attempt'])\n",
    "train_x = train_x.drop(labels='Correct First Attempt',axis = 1)\n",
    "valid_x = test.dropna() # clean empty values\n",
    "valid_y = np.array(valid_x['Correct First Attempt'])\n",
    "valid_x = valid_x.drop(labels='Correct First Attempt',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape is (232744, 15)\n",
      "train_y's shape is (232744,)\n",
      "valid_x's shape is (666, 15)\n",
      "valid_y's shape is (666,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train_x's shape is\", train_x.shape)\n",
    "print(\"train_y's shape is\", train_y.shape)\n",
    "print(\"valid_x's shape is\", valid_x.shape)\n",
    "print(\"valid_y's shape is\", valid_y.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define RMSE for later evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(x, y):\n",
    "    MSE = mean_squared_error(x,y)\n",
    "    RMSE = math.sqrt(MSE)\n",
    "    return RMSE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for adaboostRegressor is 0.38568308323957284\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "default_AdaboostRegressor_RMSE = RMSE(valid_y, valid_y_hat)\n",
    "print(\"RMSE for adaboostRegressor is\", default_AdaboostRegressor_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for adaboostClassifier is 0.4173417953838007\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "default_AdaboostClassifier_RMSE = RMSE(valid_y, valid_y_hat)\n",
    "print(\"RMSE for adaboostClassifier is\", default_AdaboostClassifier_RMSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Decision Tree is 0.4633731916228157\n"
     ]
    }
   ],
   "source": [
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "defalut_DecisionTreeClassifier_RMSE = RMSE(valid_y, valid_y_hat)\n",
    "print(\"RMSE for Decision Tree is\", defalut_DecisionTreeClassifier_RMSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for RandomForestRegressor is 0.3497440348131438\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "defalut_RandomForestRegressor_RMSE = RMSE(valid_y, valid_y_hat)\n",
    "print(\"RMSE for RandomForestRegressor is\", defalut_RandomForestRegressor_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for RandomForestClassifier is 0.4155390146215788\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "defalut_RandomForestClassifier_RMSE = RMSE(valid_y, valid_y_hat)\n",
    "print(\"RMSE for RandomForestClassifier is\", defalut_RandomForestClassifier_RMSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for XGBoost is 0.39516598557587945\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "default_XGBClassifier_RMSE = RMSE(valid_y, valid_y_hat)\n",
    "print(\"RMSE for XGBoost is\", default_XGBClassifier_RMSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for LightbgmRegressor is 0.3537449722295338\n"
     ]
    }
   ],
   "source": [
    "model = lightgbm.LGBMRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "default_LightbgmRegressor_RMSE = RMSE(valid_y, valid_y_hat)\n",
    "print(\"RMSE for LightbgmRegressor is\", default_LightbgmRegressor_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for LightbgmClassifier is 0.4026936331284146\n"
     ]
    }
   ],
   "source": [
    "model = lightgbm.LGBMClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "print(\"RMSE for LightbgmClassifier is\", RMSE(valid_y, valid_y_hat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for KNeighborsRegressor is 0.4015734817704741\n"
     ]
    }
   ],
   "source": [
    "model = neighbors.KNeighborsRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "valid_y_hat\n",
    "print(\"RMSE for KNeighborsRegressor is\", RMSE(valid_y, valid_y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for KNeighborsClassifier is 0.4568464826489405\n"
     ]
    }
   ],
   "source": [
    "model = neighbors.KNeighborsClassifier()\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "print(\"RMSE for KNeighborsClassifier is\", RMSE(valid_y, valid_y_hat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for MLPRegressor is 0.3715221816894079\n"
     ]
    }
   ],
   "source": [
    "model = MLPRegressor(hidden_layer_sizes=(100, 5, 100), activation='tanh', solver='adam')\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "print(\"RMSE for MLPRegressor is\", RMSE(valid_y, valid_y_hat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSME visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For tuning hyperparameters, here we choose the 3 algorithms to do the further step.   \n",
    "They are **AdaboostRegresser, RandomForestRegressor, LGBMRegressor**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoostRegressor part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for AdaboostRegressor\n",
    "param_dist = {\n",
    "    'n_estimators': range(20, 100, 4),\n",
    "    'learning_rate': np.linspace(0.01, 2, 20)\n",
    "    # 'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "model_adaboost = GridSearchCV(estimator=XGBClassifier(),\n",
    "                        param_grid=param_dist, scoring='neg_mean_squared_error', \n",
    "                        verbose=3, n_jobs=-1, cv=5)\n",
    "model_adaboost.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None,...\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'learning_rate': array([0.01      , 0.11473684, 0.21947368, 0.32421053, 0.42894737,\n",
       "       0.53368421, 0.63842105, 0.74315789, 0.84789474, 0.95263158,\n",
       "       1.05736842, 1.16210526, 1.26684211, 1.37157895, 1.47631579,\n",
       "       1.58105263, 1.68578947, 1.79052632, 1.89526316, 2.        ]),\n",
       "                         'n_estimators': range(20, 100, 4)},\n",
       "             scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_ # the output of Hyperparameter tuning of adaboost after 200minutes' training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"best parameter:\",model_adaboost.best_params_)\n",
    "# print(\"best score:\", model_adaboost.best_score_)\n",
    "# print(model.best_estimator_)\n",
    "# the output was learning_rate = 0.11473684 and n_estimator = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for adaboostRegressor is 0.3796168526901849\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostRegressor(learning_rate=0.11473684, n_estimators=28)\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "print(\"RMSE for adaboostRegressor is\", RMSE(valid_y, valid_y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for adaboostRegressor is 0.3733618521673437\n"
     ]
    }
   ],
   "source": [
    "# the result of the tuned hyperparameter of AdaBoostRegressor wasn't that good\n",
    "# manually use the parameters of learning_rate=0.01, n_estimators=50\n",
    "model = AdaBoostRegressor(learning_rate=0.01, n_estimators=50)\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "print(\"RMSE for adaboostRegressor is\", RMSE(valid_y, valid_y_hat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestRegressor Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 19 candidates, totalling 95 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'n_estimators': range(10, 200, 10)},\n",
       "             scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For RandomForestRegressor\n",
    "param_dist = {\n",
    "    'n_estimators' : range(10, 200 ,10)\n",
    "    # 'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson']\n",
    "}\n",
    "model_randomforest = GridSearchCV(estimator=RandomForestRegressor(),\n",
    "                        param_grid=param_dist, scoring='neg_mean_squared_error', \n",
    "                        verbose=3, n_jobs=-1, cv=5)\n",
    "model_randomforest.fit(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'n_estimators': range(10, 200, 10)},\n",
       "             scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter: {'n_estimators': 150}\n",
      "best score: -0.15268760875134982\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameter:\",model_randomforest.best_params_)\n",
    "print(\"best score:\", model_randomforest.best_score_)\n",
    "# print(model.best_estimator_)\n",
    "# the output was n_estimators=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for RandomForestRegressor is 0.3530385561029303\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=150)\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "print(\"RMSE for RandomForestRegressor is\", RMSE(valid_y, valid_y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for RandomForestRegressor is 0.35115575941502875\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "print(\"RMSE for RandomForestRegressor is\", RMSE(valid_y, valid_y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for RandomForestRegressor is 0.3535061846695293\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=190, max_depth=15, max_leaf_nodes=900)\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "print(\"RMSE for RandomForestRegressor is\", RMSE(valid_y, valid_y_hat))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LGBMRegressor Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 896 candidates, totalling 4480 fits\n",
      "[LightGBM] [Warning] Unknown parameter: n_estimator\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1,\n",
       "             param_grid={'n_estimator': range(60, 200, 5),\n",
       "                         'num_leaves': range(40, 200, 5)},\n",
       "             scoring='neg_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'num_leaves': range(40, 200, 5),\n",
    "    'n_estimator': range(60, 200, 5)\n",
    "    # 'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson']\n",
    "}\n",
    "model_LGBM = GridSearchCV(estimator=lightgbm.LGBMRegressor(),\n",
    "                        param_grid=param_dist, scoring='neg_mean_squared_error', \n",
    "                        verbose=3, n_jobs=-1, cv=5)\n",
    "model_LGBM.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameter: {'n_estimator': 60, 'num_leaves': 150}\n",
      "best score: -0.14274718547591378\n"
     ]
    }
   ],
   "source": [
    "print(\"best parameter:\",model_LGBM.best_params_)\n",
    "print(\"best score:\", model_LGBM.best_score_)\n",
    "# print(model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for LightbgmRegressor is 0.3489215935347196\n"
     ]
    }
   ],
   "source": [
    "model = lightgbm.LGBMRegressor(n_estimators=60, num_leaves=150)\n",
    "model.fit(train_x, train_y)\n",
    "valid_y_hat = model.predict(valid_x)\n",
    "tuned_LightbgmRegressor_RMSE = RMSE(valid_y, valid_y_hat)\n",
    "print(\"RMSE for LightbgmRegressor is\", tuned_LightbgmRegressor_RMSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output result to test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_testCSV():\n",
    "    output_x = test\n",
    "    output_y = np.array(output_x['Correct First Attempt']).astype(float)\n",
    "    output_x = output_x.drop(['Correct First Attempt'], axis=1)\n",
    "    model = lightgbm.LGBMRegressor(n_estimators=60, num_leaves=150)\n",
    "    model.fit(train_x, train_y)\n",
    "    output_res = model.predict(output_x)\n",
    "    for id, val in enumerate(output_y):\n",
    "        if np.isnan(val):\n",
    "            output_y[id] = output_res[id]\n",
    "    new_test = pd.read_csv('./data/test.csv', sep='\\t')\n",
    "    new_test['Correct First Attempt'] = output_y\n",
    "    new_test.to_csv('test.csv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_testCSV()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs150a",
   "language": "python",
   "name": "cs150a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3038ab2f43a43659d5a856f274b6c5917471f65d96f5683024a484c4760fca65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
