{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\environment\\anaconda3\\lib\\site-packages\\pyspark\\sql\\context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SQLContext, SparkContext\n",
    "from pyspark.sql.functions import mean, col, udf\n",
    "from pyspark.sql.types import *\n",
    "import numpy as np\n",
    "import pandas\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "spark_context = SparkContext('local')\n",
    "sqlc = SQLContext(spark_context)\n",
    "train = sqlc.read.csv('data/train.csv', sep='\\t', header=True)\n",
    "test = sqlc.read.csv('data/test.csv', sep='\\t', header=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Problem Hieararchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def get_unit(str):\n",
    "    return str.split(\",\")[0]\n",
    "\n",
    "@udf\n",
    "def get_section(str):\n",
    "     return str.split(\",\")[1]\n",
    "\n",
    "train = train.withColumn(\"Problem Unit\",get_unit(train[\"Problem Hierarchy\"]))\n",
    "train = train.withColumn(\"Problem Section\",get_section(train[\"Problem Hierarchy\"]))\n",
    "test = test.withColumn(\"Problem Unit\",get_unit(test[\"Problem Hierarchy\"]))\n",
    "test = test.withColumn(\"Problem Section\",get_section(test[\"Problem Hierarchy\"]))\n",
    "# train = train.drop('Problem Hierarchy')\n",
    "# test = test.drop('Problem Hierarchy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get the number of KC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def KC_num(str):\n",
    "    if str:\n",
    "        return str.count(\"~~\")+1\n",
    "    else:\n",
    "        return 0\n",
    "train = train.withColumn(\"KC num\",KC_num(train['KC(Default)']))\n",
    "test = test.withColumn(\"KC num\",KC_num(test['KC(Default)']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get oportunity min and avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf \n",
    "def opp_avg(str):\n",
    "    if str:\n",
    "        str_list = str.split(\"~~\")\n",
    "        num_list = []\n",
    "        for s in str_list:\n",
    "            num = int(s)\n",
    "            num_list.append(num)\n",
    "        return 1.0 * sum(num_list)/len(num_list)\n",
    "    else:\n",
    "        return 0\n",
    "train = train.withColumn(\"Opportunity Average\",opp_avg(train['Opportunity(Default)']))\n",
    "test = test.withColumn(\"Opportunity Average\",opp_avg(test['Opportunity(Default)']))\n",
    "\n",
    "@udf \n",
    "def opp_min(str):\n",
    "    if str:\n",
    "        str_list = str.split(\"~~\")\n",
    "        num_list = []\n",
    "        for s in str_list:\n",
    "            num = int(s)\n",
    "            num_list.append(num)\n",
    "        return min(num_list)\n",
    "    else:\n",
    "        return 0\n",
    "train = train.withColumn(\"Opportunity Min\",opp_min(train[\"Opportunity(Default)\"]))\n",
    "test = test.withColumn(\"Opportunity Min\",opp_min(test[\"Opportunity(Default)\"]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step Name Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf\n",
    "def step_name_rename(str):\n",
    "    if str:\n",
    "        basic_op = [\"+\",\"-\",\"*\",\"/\",\"^\",\"=\"]\n",
    "        for op in basic_op:\n",
    "            if op in str:\n",
    "                return \"basic op\"\n",
    "        return str\n",
    "\n",
    "train = train.withColumn(\"renamed Step Name\",step_name_rename(train[\"Step Name\"]))\n",
    "train = train.drop(\"Step Name\")\n",
    "train = train.withColumnRenamed(\"renamed Step Name\",\"Step Name\")\n",
    "test = test.withColumn(\"renamed Step Name\",step_name_rename(test[\"Step Name\"]))\n",
    "test = test.drop(\"Step Name\")\n",
    "test = test.withColumnRenamed(\"renamed Step Name\",\"Step Name\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(column):\n",
    "    global train,test\n",
    "    index = {}\n",
    "    all_rows = train.union(test).select(column).distinct().collect()\n",
    "    col_value = []\n",
    "    for item in all_rows:\n",
    "        col_value.append(item[column])\n",
    "    for i, val in enumerate(col_value):\n",
    "        index[val] = i\n",
    "    @udf\n",
    "    def get_id(str):\n",
    "        return index[str]\n",
    "    \n",
    "    encoded_column = \"encoded\" + \" \" + column \n",
    "    train = train.withColumn(encoded_column, get_id(train[column]))\n",
    "    train = train.drop(column)\n",
    "    train = train.withColumnRenamed(encoded_column, column)\n",
    "    test = test.withColumn(encoded_column, get_id(test[column]))\n",
    "    test = test.drop(column)\n",
    "    test = test.withColumnRenamed(encoded_column, column)\n",
    "\n",
    "col_encode = ['Anon Student Id','Problem Name','Problem Unit','Problem Section','Step Name']\n",
    "for col in col_encode:\n",
    "    encode(col)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train = train.filter(train[\"Correct First Attempt\"] == \"1\")\n",
    "def CFAR(column):\n",
    "    global train,test,correct_train\n",
    "    correct_group = correct_train.groupBy(column).count().collect()\n",
    "    all_group = train.groupBy(column).count().collect()\n",
    "    CFAR = {}\n",
    "    for col in all_group:\n",
    "        CFAR[col[column]] = [col['count'],0,0]\n",
    "    for col in correct_group:\n",
    "        CFAR[col[column]][1] = col['count']\n",
    "    for col in all_group:\n",
    "        CFAR[col[column]][2] = float(CFAR[col[column]][1] / CFAR[col[column]][0])\n",
    "    sum = 0\n",
    "    for col_value in CFAR:\n",
    "        sum += CFAR[col_value][2]\n",
    "    avg = float(sum / len(CFAR))\n",
    "    @udf\n",
    "    def get_rate(value):\n",
    "        if value in CFAR:\n",
    "            return CFAR[value][2]\n",
    "        else:\n",
    "            return avg\n",
    "    train = train.withColumn(column + \" CFAR\",get_rate(train[column]))\n",
    "    test = test.withColumn(column +\" CFAR\",get_rate(test[column]))\n",
    "\n",
    "CFAR_list = ['Anon Student Id','Problem Name','Problem Unit','Problem Section','Step Name','KC(Default)']\n",
    "for col in CFAR_list:\n",
    "    CFAR(col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop useless columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Row','Step Start time','First Transaction Time','Correct Transaction Time','Step End Time','Step Duration (sec)',\\\n",
    "    'Correct Step Duration (sec)','Error Step Duration (sec)','Incorrects','Hints','Corrects','KC(Default)',\"Opportunity(Default)\",\"Problem Hierarchy\"]\n",
    "\n",
    "for col in columns_to_drop:\n",
    "    train =  train.drop(col)\n",
    "    test = test.drop(col)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.toPandas().to_csv('data/train_preprocess.csv', sep='\\t', header=True, index = False)\n",
    "test.toPandas().to_csv('data/test_preprocess.csv', sep='\\t', header=True, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs150a",
   "language": "python",
   "name": "cs150a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3038ab2f43a43659d5a856f274b6c5917471f65d96f5683024a484c4760fca65"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
